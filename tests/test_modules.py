import numpy as np
import torch
import traceback
import sys

import tinytorch
from tinytorch.tensor import Tensor
import tinytorch.nn as nn

DTYPE = np.float64
TORCH_DTYPE = torch.float64

def print_named_params(mod):
    for n, p in mod.named_parameters():
        if isinstance(p, Tensor):
            print(n, p.data.shape)
        else:
            print(n, p.shape)

def test_simple_ffn():
    class SimpleFFN_tinytorch(nn.Module):
        def __init__(self):
            super().__init__()
            self.fc1 = nn.Linear(256, 128)
            self.fc_2 = nn.Linear(128, 10)
            self.relu = nn.ReLU()
            
        def forward(self, x):
            out = self.fc2(self.relu(self.fc_1(x)))
            return out
        
    class SimpleFFN_torch(torch.nn.Module):
        def __init__(self):
            super().__init__()
            self.fc1 = torch.nn.Linear(256, 128)
            self.fc2 = torch.nn.Linear(128, 10)
            self.relu = torch.nn.ReLU()
            
        def forward(self, x):
            out = self.fc2(self.relu(self.fc_1(x)))
            return out
        
    ffn_tt = SimpleFFN_tinytorch()
    ffn_t = SimpleFFN_torch()
    print_named_params(ffn_tt)
    print("*"*80)
    print_named_params(ffn_t)
    
def test_ffn_with_params():
    class MyModule_tinytorch(nn.Module):
        def __init__(self):
            super().__init__()
            self.layer = nn.Linear(126, 256)
            self.params = nn.Parameter(np.random.randn(128, 256).astype(DTYPE))
        
        def forward(self, x):
            return x
        
    class MyModule_torch(torch.nn.Module):
        def __init__(self):
            super().__init__()
            self.layer = torch.nn.Linear(126, 256)
            self.params = torch.nn.Parameter(torch.randn(128, 256, dtype=TORCH_DTYPE))
        
        def forward(self, x):
            return x
        
    mod_tt = MyModule_tinytorch()
    mod_t = MyModule_torch()
    print_named_params(mod_tt)
    print("*"*80)
    print_named_params(mod_t)
    
def test_loading_saving_simple():
    x = Tensor(np.random.randn(10, 10).astype(DTYPE))
    tinytorch.save(x, "test_tensor.pkl")
    loaded = tinytorch.load("test_tensor.pkl")
    assert loaded is not None
    assert np.array_equal(x.data, loaded.data)
    
def test_loading_saving_module():
    class MyModule_tinytorch(nn.Module):
        def __init__(self):
            super().__init__()
            self.layer = nn.Linear(126, 256)
            self.params = nn.Parameter(np.random.randn(128, 256).astype(DTYPE))
        
        def forward(self, x):
            return x
        
    mod_tt = MyModule_tinytorch()
    tinytorch.save(mod_tt.state_dict(), "test_module.pkl")
    loaded = MyModule_tinytorch()
    loaded.load_state_dict(tinytorch.load("test_module.pkl"))
    assert loaded is not None
    print_named_params(loaded)
    print("*"*80)
    print_named_params(mod_tt)
    
    for (n1, p1), (n2, p2) in zip(mod_tt.named_parameters(), loaded.named_parameters()):
        assert n1 == n2
        assert np.array_equal(p1.data, p2.data)
        
# test generated by Claude Sonnet 4.5
# def test_loading_saving_optimizer():
#     from tinytorch.optim import SGD, Adam, RMSprop
    
#     def run_optimizer_save_load_test(optimizer_class, optimizer_kwargs, test_name):
#         """Helper function to test save/load for any optimizer"""
#         print(f"\nTesting {test_name}...")
        
#         class SimpleModel(nn.Module):
#             def __init__(self):
#                 super().__init__()
#                 self.fc1 = nn.Linear(10, 5)
#                 self.fc2 = nn.Linear(5, 2)
            
#             def forward(self, x):
#                 return self.fc2(self.fc1(x))
        
#         # Set random seed for reproducibility
#         np.random.seed(42)
        
#         # Create model and optimizer
#         model = SimpleModel()
#         optimizer = optimizer_class(model.parameters(), **optimizer_kwargs)
        
#         # Train for a few steps to populate optimizer state
#         losses_before = []
#         for step in range(3):
#             x = Tensor(np.random.randn(4, 10).astype(DTYPE), requires_grad=False)
#             y = model(x)
#             loss = (y ** 2).sum()
#             losses_before.append(loss.data.item() if hasattr(loss.data, 'item') else float(loss.data))
            
#             loss.backward()
#             optimizer.step()
#             optimizer.zero_grad()
        
#         # Save model and optimizer state
#         model_state = model.state_dict()
#         optimizer_state = optimizer.state_dict()
#         tinytorch.save(model_state, "test_model.pkl")
#         tinytorch.save(optimizer_state, "test_optimizer.pkl")
        
#         # Get current parameter values and optimizer state for comparison
#         param_values_before = [p.data.copy() for p in model.parameters()]
        
#         # Extract state values (e.g., velocity buffers)
#         state_values_before = {}
#         for param_id, state in optimizer.state.items():
#             state_values_before[param_id] = {k: v.copy() if isinstance(v, np.ndarray) else v 
#                                              for k, v in state.items()}
        
#         # Create new model and optimizer (fresh initialization)
#         np.random.seed(123)  # Different seed to ensure different initialization
#         model_new = SimpleModel()
#         optimizer_new = optimizer_class(model_new.parameters(), **optimizer_kwargs)
        
#         # Verify parameters are different before loading
#         params_different = False
#         for p1, p2 in zip(model.parameters(), model_new.parameters()):
#             if not np.allclose(p1.data, p2.data):
#                 params_different = True
#                 break
#         assert params_different, "Models should have different initial parameters"
        
#         # Load model and optimizer state
#         loaded_model_state = tinytorch.load("test_model.pkl")
#         loaded_optimizer_state = tinytorch.load("test_optimizer.pkl")
#         model_new.load_state_dict(loaded_model_state)
#         optimizer_new.load_state_dict(loaded_optimizer_state)
        
#         # Verify model parameters match after loading
#         for p_before, p_after in zip(param_values_before, model_new.parameters()):
#             assert np.allclose(p_before, p_after.data), "Model parameters don't match after loading"
        
#         # Verify optimizer state structure matches
#         assert len(optimizer.state) == len(optimizer_new.state), "State dict lengths don't match"
#         assert len(optimizer.param_groups) == len(optimizer_new.param_groups), "Param groups don't match"
        
#         # Verify optimizer hyperparameters match
#         for pg1, pg2 in zip(optimizer.param_groups, optimizer_new.param_groups):
#             for key in optimizer_kwargs.keys():
#                 if key == 'betas':  # Special handling for tuples
#                     assert pg1[key] == pg2[key], f"{key} values don't match"
#                 else:
#                     assert pg1[key] == pg2[key], f"{key} values don't match"
#             assert len(pg1["params"]) == len(pg2["params"]), "Number of params don't match"
        
#         # Verify optimizer state values match (velocity, momentum buffers, etc.)
#         # Map old param IDs to new param IDs by position
#         old_param_ids = [id(p) for p in model.parameters()]
#         new_param_ids = [id(p) for p in model_new.parameters()]
        
#         for old_id, new_id in zip(old_param_ids, new_param_ids):
#             if old_id in state_values_before:
#                 assert new_id in optimizer_new.state, f"State missing for parameter"
#                 old_state = state_values_before[old_id]
#                 new_state = optimizer_new.state[new_id]
                
#                 for key in old_state.keys():
#                     if isinstance(old_state[key], np.ndarray):
#                         assert np.allclose(old_state[key], new_state[key]), \
#                             f"State value '{key}' doesn't match after loading"
#                     else:
#                         assert old_state[key] == new_state[key], \
#                             f"State value '{key}' doesn't match after loading"
        
#         # Continue training with loaded optimizer and verify trajectory matches
#         # We'll do this by comparing with continuing from original optimizer
#         np.random.seed(100)  # Reset seed for identical data
        
#         # Continue with original optimizer
#         losses_original = []
#         for step in range(2):
#             x = Tensor(np.random.randn(4, 10).astype(DTYPE), requires_grad=False)
#             y = model(x)
#             loss = (y ** 2).sum()
#             losses_original.append(loss.data.item() if hasattr(loss.data, 'item') else float(loss.data))
            
#             loss.backward()
#             optimizer.step()
#             optimizer.zero_grad()
        
#         # Reset seed and continue with loaded optimizer
#         np.random.seed(100)
#         losses_loaded = []
#         for step in range(2):
#             x = Tensor(np.random.randn(4, 10).astype(DTYPE), requires_grad=False)
#             y = model_new(x)
#             loss = (y ** 2).sum()
#             losses_loaded.append(loss.data.item() if hasattr(loss.data, 'item') else float(loss.data))
            
#             loss.backward()
#             optimizer_new.step()
#             optimizer_new.zero_grad()
        
#         # Verify training trajectories match
#         for l1, l2 in zip(losses_original, losses_loaded):
#             assert np.isclose(l1, l2, rtol=1e-6), \
#                 f"Training trajectories diverge: {l1} vs {l2}"
        
#         # Verify final parameters match
#         for p1, p2 in zip(model.parameters(), model_new.parameters()):
#             assert np.allclose(p1.data, p2.data, rtol=1e-6), \
#                 "Final parameters don't match after continued training"
        
#         print(f"  ✓ State structure preserved")
#         print(f"  ✓ Hyperparameters match")
#         print(f"  ✓ State values (buffers) match")
#         print(f"  ✓ Training trajectory identical after loading")
#         print(f"  ✓ {test_name} passed!")
    
#     # Test different optimizers
#     run_optimizer_save_load_test(SGD, {"lr": 0.01, "momentum": 0.9}, "SGD with momentum")
#     run_optimizer_save_load_test(SGD, {"lr": 0.01, "momentum": 0.0}, "SGD without momentum")
#     run_optimizer_save_load_test(Adam, {"lr": 0.001, "betas": (0.9, 0.999)}, "Adam")
#     run_optimizer_save_load_test(RMSprop, {"lr": 0.01, "alpha": 0.99, "momentum": 0.9}, "RMSprop")
    
#     print("\n" + "="*60)
#     print("All optimizer save/load tests passed!")
#     print("="*60)

def test_loading_saving_optimizer():
    from tinytorch.optim import SGD
    
    class SimpleModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.fc1 = nn.Linear(10, 5)
            self.fc2 = nn.Linear(5, 2)
        
        def forward(self, x):
            return self.fc2(self.fc1(x))
    
    model = SimpleModel()
    optim = SGD(model.parameters(), lr=0.01, momentum=0.9)
    print(optim)
    print("*"*80)
    tinytorch.save(optim.state_dict(), "test_optim.pkl")
    loaded_optim = SGD(model.parameters(), lr=0.01, momentum=0.9)
    loaded_optim.load_state_dict(tinytorch.load("test_optim.pkl"))
    print(loaded_optim)


def main():
    torch.set_default_dtype(TORCH_DTYPE)
    
    tests = [
        ("simple_ffn",  test_simple_ffn),
        ("ffn_with_params", test_ffn_with_params),
        ("loading_saving_simple", test_loading_saving_simple),
        ("loading_saving_module", test_loading_saving_module),
        ("loading_saving_optim", test_loading_saving_optimizer),
    ]
    
    for name, fn in tests:
        print("="*80)
        print(name)
        print("="*80)
        fn()
        
if __name__ == "__main__":
    main()
        

